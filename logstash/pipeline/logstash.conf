input {
	beats {
		port => 5044
	}

	tcp {
		port => 5000
	}

	file {
		path => "/mounted_logs/docker-cluster_audit.json"
	}
}

## Add your filters / logstash plugins configuration here

filter {
	json {
		source => "message"
		tag_on_failure => ["_jsonparsefailure"]
		target => "parsedjson"
	}

	if [parsedjson][url.path] =~ "^.*\/_async_search$"  {
		# json {
		# 	source => "[parsedjson][request.body]"
		# 	target => "requestdetails"
		# 	tag_on_failure => ["_jsonbodyparsefailure"]
		# }

		mutate {
			copy => { "[parsedjson][user.name]" => "[user.name]" }
			copy => { "[parsedjson][url.query]" => "[url.query]" }
			copy => { "[parsedjson][url.path]" => "[url.path]" }
			copy => { "[parsedjson][origin.address]" => "[origin.address]" }
			copy => { "[parsedjson][user.realm]" => "[user.realm]" }
			copy => { "[parsedjson][request.body]" => "[request.body]" }
			remove_field => [parsedjson]
		}

	} else {

		drop {}

	}

	# grok {
	# 	match => {
	# 		[parsed_json][message] => '.* request.body=\"%{GREEDYDATA:request_body}\" request.id=.*url.path=\"%{GREEDYDATA:url_path}\" url.query=.* user.name=\"%{GREEDYDATA:username}\" .*'
	# 	}
	# }

	# 	match => {
	# 		"message" => "%{GREEDYDATA:grokked2_before_string}type%{GREEDYDATA:grokked2_the_rest}"
	# 	}
	# }
}

output {
    stdout {
        codec => rubydebug
    }
	elasticsearch {
		hosts => "elasticsearch-ingest:9200"
		user => "elastic"
		password => "changeme"
	}
}
